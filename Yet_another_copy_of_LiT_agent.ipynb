{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyONvaJbgXnRr3sodI8Z0yZm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maharishiva/LiT-agent/blob/main/Yet_another_copy_of_LiT_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIHbmSDyhv8m",
        "outputId": "bffc90fc-e032-45b9-d973-76e5e2f0d8f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LiT-agent'...\n",
            "remote: Enumerating objects: 272, done.\u001b[K\n",
            "remote: Counting objects: 100% (165/165), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 272 (delta 91), reused 109 (delta 42), pack-reused 107 (from 1)\u001b[K\n",
            "Receiving objects: 100% (272/272), 268.24 MiB | 36.51 MiB/s, done.\n",
            "Resolving deltas: 100% (103/103), done.\n",
            "/content/LiT-agent\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Maharishiva/LiT-agent.git\n",
        "%cd LiT-agent"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92GR8HX64qch",
        "outputId": "83d258f8-4403-4f41-9341-986c6c601b61"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb7bwCns55OO",
        "outputId": "f7bdd50a-c3fc-4ee6-d425-733afad44b22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "Hd9_ukAl6B78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c19aa80-960c-4128-ea54-c76092110fa3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\t\t      play_game.py\t      simulation.py\n",
            "CLAUDE.md\t      README.md\t\t      trainer_PPO_trXL.py\n",
            "colab_notebook.ipynb  rel_multi_head.py       train_PPO_trXL.py\n",
            "LICENSE\t\t      requirements_colab.txt  transformerXL.py\n",
            "llm_context.sh\t      requirements.txt\t      wrappers.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements_colab.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qoyQXi-ch1gf",
        "outputId": "e5f7f7a7-71d5-48a5-9c79-73257e2ae329"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chex==0.1.86 (from -r requirements_colab.txt (line 1))\n",
            "  Downloading chex-0.1.86-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting craftax==1.4.3 (from -r requirements_colab.txt (line 2))\n",
            "  Downloading craftax-1.4.3-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting gymnasium==0.29.1 (from -r requirements_colab.txt (line 3))\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting gymnax==0.0.7 (from -r requirements_colab.txt (line 4))\n",
            "  Downloading gymnax-0.0.7-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting kiwisolver==1.4.5 (from -r requirements_colab.txt (line 5))\n",
            "  Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting matplotlib==3.8.4 (from -r requirements_colab.txt (line 6))\n",
            "  Downloading matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting orbax-checkpoint==0.5.9 (from -r requirements_colab.txt (line 7))\n",
            "  Downloading orbax_checkpoint-0.5.9-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements_colab.txt (line 8)) (0.13.2)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex==0.1.86->-r requirements_colab.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from chex==0.1.86->-r requirements_colab.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: jax>=0.4.16 in /usr/local/lib/python3.11/dist-packages (from chex==0.1.86->-r requirements_colab.txt (line 1)) (0.5.2)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.11/dist-packages (from chex==0.1.86->-r requirements_colab.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.24.1 in /usr/local/lib/python3.11/dist-packages (from chex==0.1.86->-r requirements_colab.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chex==0.1.86->-r requirements_colab.txt (line 1)) (0.12.1)\n",
            "Collecting distrax (from craftax==1.4.3->-r requirements_colab.txt (line 2))\n",
            "  Downloading distrax-0.1.5-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.11/dist-packages (from craftax==1.4.3->-r requirements_colab.txt (line 2)) (0.2.5)\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.11/dist-packages (from craftax==1.4.3->-r requirements_colab.txt (line 2)) (0.10.6)\n",
            "Collecting black (from craftax==1.4.3->-r requirements_colab.txt (line 2))\n",
            "  Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pre-commit (from craftax==1.4.3->-r requirements_colab.txt (line 2))\n",
            "  Downloading pre_commit-4.2.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting argparse (from craftax==1.4.3->-r requirements_colab.txt (line 2))\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from craftax==1.4.3->-r requirements_colab.txt (line 2)) (0.21.0)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (from craftax==1.4.3->-r requirements_colab.txt (line 2)) (2.6.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.11/dist-packages (from craftax==1.4.3->-r requirements_colab.txt (line 2)) (2.37.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1->-r requirements_colab.txt (line 3)) (3.1.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium==0.29.1->-r requirements_colab.txt (line 3)) (0.0.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from gymnax==0.0.7->-r requirements_colab.txt (line 4)) (6.0.2)\n",
            "Collecting gym>=0.26 (from gymnax==0.0.7->-r requirements_colab.txt (line 4))\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r requirements_colab.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r requirements_colab.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r requirements_colab.txt (line 6)) (4.58.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r requirements_colab.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r requirements_colab.txt (line 6)) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r requirements_colab.txt (line 6)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.8.4->-r requirements_colab.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint==0.5.9->-r requirements_colab.txt (line 7)) (1.12.2)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint==0.5.9->-r requirements_colab.txt (line 7)) (1.1.1)\n",
            "Requirement already satisfied: tensorstore>=0.1.51 in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint==0.5.9->-r requirements_colab.txt (line 7)) (0.1.74)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint==0.5.9->-r requirements_colab.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from orbax-checkpoint==0.5.9->-r requirements_colab.txt (line 7)) (5.29.5)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn->-r requirements_colab.txt (line 8)) (2.2.2)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym>=0.26->gymnax==0.0.7->-r requirements_colab.txt (line 4)) (0.0.8)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.16->chex==0.1.86->-r requirements_colab.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.16->chex==0.1.86->-r requirements_colab.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.16->chex==0.1.86->-r requirements_colab.txt (line 1)) (1.15.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->-r requirements_colab.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->-r requirements_colab.txt (line 8)) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib==3.8.4->-r requirements_colab.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black->craftax==1.4.3->-r requirements_colab.txt (line 2)) (8.2.1)\n",
            "Collecting mypy-extensions>=0.4.3 (from black->craftax==1.4.3->-r requirements_colab.txt (line 2))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting pathspec>=0.9.0 (from black->craftax==1.4.3->-r requirements_colab.txt (line 2))\n",
            "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black->craftax==1.4.3->-r requirements_colab.txt (line 2)) (4.3.8)\n",
            "Requirement already satisfied: tensorflow-probability>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from distrax->craftax==1.4.3->-r requirements_colab.txt (line 2)) (0.25.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint==0.5.9->-r requirements_colab.txt (line 7)) (2025.3.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint==0.5.9->-r requirements_colab.txt (line 7)) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[epath,epy]->orbax-checkpoint==0.5.9->-r requirements_colab.txt (line 7)) (3.23.0)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.11/dist-packages (from flax->craftax==1.4.3->-r requirements_colab.txt (line 2)) (13.9.4)\n",
            "Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from flax->craftax==1.4.3->-r requirements_colab.txt (line 2)) (0.1.9)\n",
            "INFO: pip is looking at multiple versions of optax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting optax (from craftax==1.4.3->-r requirements_colab.txt (line 2))\n",
            "  Downloading optax-0.2.4-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading optax-0.2.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit->craftax==1.4.3->-r requirements_colab.txt (line 2))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit->craftax==1.4.3->-r requirements_colab.txt (line 2))\n",
            "  Downloading identify-2.6.12-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit->craftax==1.4.3->-r requirements_colab.txt (line 2))\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit->craftax==1.4.3->-r requirements_colab.txt (line 2))\n",
            "  Downloading virtualenv-20.31.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->craftax==1.4.3->-r requirements_colab.txt (line 2)) (3.1.44)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb->craftax==1.4.3->-r requirements_colab.txt (line 2)) (2.11.7)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->craftax==1.4.3->-r requirements_colab.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->craftax==1.4.3->-r requirements_colab.txt (line 2)) (2.32.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->craftax==1.4.3->-r requirements_colab.txt (line 2)) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->craftax==1.4.3->-r requirements_colab.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->craftax==1.4.3->-r requirements_colab.txt (line 2)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb->craftax==1.4.3->-r requirements_colab.txt (line 2)) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->craftax==1.4.3->-r requirements_colab.txt (line 2)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->craftax==1.4.3->-r requirements_colab.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->craftax==1.4.3->-r requirements_colab.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb->craftax==1.4.3->-r requirements_colab.txt (line 2)) (2025.7.9)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax->craftax==1.4.3->-r requirements_colab.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1->flax->craftax==1.4.3->-r requirements_colab.txt (line 2)) (2.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability>=0.15.0->distrax->craftax==1.4.3->-r requirements_colab.txt (line 2)) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability>=0.15.0->distrax->craftax==1.4.3->-r requirements_colab.txt (line 2)) (0.6.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability>=0.15.0->distrax->craftax==1.4.3->-r requirements_colab.txt (line 2)) (0.1.9)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->craftax==1.4.3->-r requirements_colab.txt (line 2))\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit->craftax==1.4.3->-r requirements_colab.txt (line 2)) (3.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->craftax==1.4.3->-r requirements_colab.txt (line 2)) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax->craftax==1.4.3->-r requirements_colab.txt (line 2)) (0.1.2)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-probability>=0.15.0->distrax->craftax==1.4.3->-r requirements_colab.txt (line 2)) (25.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree->tensorflow-probability>=0.15.0->distrax->craftax==1.4.3->-r requirements_colab.txt (line 2)) (1.17.2)\n",
            "Downloading chex-0.1.86-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading craftax-1.4.3-py3-none-any.whl (8.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnax-0.0.7-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.3/96.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m133.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orbax_checkpoint-0.5.9-py3-none-any.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.0/168.0 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distrax-0.1.5-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optax-0.2.3-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.2.0-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.7/220.7 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading identify-2.6.12-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
            "Downloading virtualenv-20.31.2-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m128.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827729 sha256=2f4f190e21034e9a6208f006c04227dd0bed84273ad5831a6c70c2b3acd00137\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/77/9e/9af5470201a0b0543937933ee99ba884cd237d2faefe8f4d37\n",
            "Successfully built gym\n",
            "Installing collected packages: distlib, argparse, virtualenv, pathspec, nodeenv, mypy-extensions, kiwisolver, identify, gymnasium, gym, cfgv, pre-commit, matplotlib, black, orbax-checkpoint, chex, optax, distrax, gymnax, craftax\n",
            "  Attempting uninstall: kiwisolver\n",
            "    Found existing installation: kiwisolver 1.4.8\n",
            "    Uninstalling kiwisolver-1.4.8:\n",
            "      Successfully uninstalled kiwisolver-1.4.8\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.2.0\n",
            "    Uninstalling gymnasium-1.2.0:\n",
            "      Successfully uninstalled gymnasium-1.2.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.10.0\n",
            "    Uninstalling matplotlib-3.10.0:\n",
            "      Successfully uninstalled matplotlib-3.10.0\n",
            "  Attempting uninstall: orbax-checkpoint\n",
            "    Found existing installation: orbax-checkpoint 0.11.16\n",
            "    Uninstalling orbax-checkpoint-0.11.16:\n",
            "      Successfully uninstalled orbax-checkpoint-0.11.16\n",
            "  Attempting uninstall: chex\n",
            "    Found existing installation: chex 0.1.89\n",
            "    Uninstalling chex-0.1.89:\n",
            "      Successfully uninstalled chex-0.1.89\n",
            "  Attempting uninstall: optax\n",
            "    Found existing installation: optax 0.2.5\n",
            "    Uninstalling optax-0.2.5:\n",
            "      Successfully uninstalled optax-0.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed argparse-1.4.0 black-25.1.0 cfgv-3.4.0 chex-0.1.86 craftax-1.4.3 distlib-0.3.9 distrax-0.1.5 gym-0.26.2 gymnasium-0.29.1 gymnax-0.0.7 identify-2.6.12 kiwisolver-1.4.5 matplotlib-3.8.4 mypy-extensions-1.1.0 nodeenv-1.9.1 optax-0.2.3 orbax-checkpoint-0.5.9 pathspec-0.12.1 pre-commit-4.2.0 virtualenv-20.31.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits"
                ]
              },
              "id": "fdbbd0c916b9480c9958ad51730f00b5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3M32aGf2h-_f",
        "outputId": "01576f97-4698-4c86-d3dd-a72a902b47a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaharishiva\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd LiT-agent/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5D-tHI1iL7t",
        "outputId": "ed7476d8-55e9-4d7f-f474-b929d025afb5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LiT-agent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout main"
      ],
      "metadata": {
        "id": "gw-qtx0RWW8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "400525ab-e7ad-483f-8293-e630bc6fda12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! export JAX_TRACEBACK_FILTERING=off"
      ],
      "metadata": {
        "id": "ROrMl9gbgFFo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout main && python train_PPO_trXL.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmFHr053iVQW",
        "outputId": "81368cbb-8a2e-46c1-f758-5e1e982a4ecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already on 'main'\n",
            "Your branch is up to date with 'origin/main'.\n",
            "2025-07-13 11:23:06.013655: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1752405786.034330    5362 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1752405786.040572    5362 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Available devices: [CudaDevice(id=0)]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmaharishiva\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.21.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/LiT-agent/wandb/run-20250713_112312-upfknn5l\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcraftax_seed0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/maharishiva/lit-transformer-ppo\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/maharishiva/lit-transformer-ppo/runs/upfknn5l\u001b[0m\n",
            "Saving results to results_craftax/craftax\n",
            "Start compiling and training\n",
            "Loading textures from cache.\n",
            "Textures successfully loaded from cache.\n",
            "Compilation finished in 7.26 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "pqHvIxBq7NAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H-s4oNLQ7NHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git branch"
      ],
      "metadata": {
        "id": "blSnJqHTiXzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b206566a-c25a-4bb1-9f02-5a216c7f81ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "jax.devices()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrNeYHzWjMkt",
        "outputId": "004ff8f1-33e7-4831-f1ea-66b4f3a649dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[CudaDevice(id=0)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd LiT-agent/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Xg8UlzIjdH5",
        "outputId": "d7b0b6dd-c6f7-42e0-ea83-0b74a483ee2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LiT-agent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import imageio\n",
        "from craftax.craftax.envs.craftax_symbolic_env import CraftaxSymbolicEnv\n",
        "from craftax.craftax.renderer import render_craftax_pixels, render_craftax_symbolic\n",
        "from transformerXL import Transformer\n",
        "from trainer_PPO_trXL import ActorCriticTransformer\n",
        "\n",
        "# Load saved model parameters and config\n",
        "params = jnp.load(\"results_craftax/craftax/0_params.npy\", allow_pickle=True).item()\n",
        "config = jnp.load(\"results_craftax/craftax/0_config.npy\", allow_pickle=True).item()\n",
        "\n",
        "# Set up environment (assumed jitted) and its parameters\n",
        "env = CraftaxSymbolicEnv()\n",
        "env_params = env.default_params\n",
        "\n",
        "# Create model\n",
        "network = ActorCriticTransformer(\n",
        "    action_dim=env.action_space(env_params).n,\n",
        "    activation=config[\"ACTIVATION\"],\n",
        "    encoder_size=config[\"EMBED_SIZE\"],\n",
        "    hidden_layers=config[\"hidden_layers\"],\n",
        "    num_heads=config[\"num_heads\"],\n",
        "    qkv_features=config[\"qkv_features\"],\n",
        "    num_layers=config[\"num_layers\"],\n",
        "    gating=config[\"gating\"],\n",
        "    gating_bias=config[\"gating_bias\"],\n",
        ")\n",
        "\n",
        "# Initialize random key and environment\n",
        "rng = jax.random.PRNGKey(1202)\n",
        "rng, _rng = jax.random.split(rng)\n",
        "obs, state = env.reset(_rng, env_params)\n",
        "\n",
        "# Duplicate observation to create a dummy batch of size 2 (needed by the transformer)\n",
        "obs = obs[None, :]\n",
        "obs = jnp.concatenate([obs, obs], axis=0)\n",
        "\n",
        "# Initialize memories and mask\n",
        "memories = jnp.zeros((2, config[\"WINDOW_MEM\"], config[\"num_layers\"], config[\"EMBED_SIZE\"]))\n",
        "memories_mask = jnp.zeros((2, config[\"num_heads\"], 1, config[\"WINDOW_MEM\"] + 1), dtype=jnp.bool_)\n",
        "\n",
        "# Define a single simulation step that is fully JIT-compilable.\n",
        "@jax.jit\n",
        "def sim_step(carry, _):\n",
        "    rng, memories, obs, state = carry\n",
        "\n",
        "    # Get model output (batched call)\n",
        "    rng, _rng = jax.random.split(rng)\n",
        "    pi, _, memories_out = network.apply(\n",
        "        params, memories, obs, memories_mask, method=network.model_forward_eval\n",
        "    )\n",
        "    # Sample action from the first batch element (batch elements are identical)\n",
        "    action = pi.sample(seed=_rng)[0]\n",
        "\n",
        "    # Update memories: roll the time dimension and update the last slot.\n",
        "    memories = jnp.roll(memories, -1, axis=1)\n",
        "    new_mem = memories_out[0]  # shape: (num_layers, EMBED_SIZE)\n",
        "    new_mem_batched = jnp.broadcast_to(new_mem, (2,) + new_mem.shape)\n",
        "    memories = memories.at[:, -1].set(new_mem_batched)\n",
        "\n",
        "    # Step the environment (jitted) and re-batch the observation\n",
        "    rng, _rng = jax.random.split(rng)\n",
        "    obs_unbatched, state, reward, done, info = env.step(_rng, state, action, env_params)\n",
        "    obs = jnp.concatenate([obs_unbatched[None, :], obs_unbatched[None, :]], axis=0)\n",
        "\n",
        "    new_carry = (rng, memories, obs, state)\n",
        "    # For later rendering, we record the state at this step.\n",
        "    output = state\n",
        "    return new_carry, output\n",
        "\n",
        "# Run the entire simulation loop with jax.lax.scan for 100 steps.\n",
        "carry = (rng, memories, obs, state)\n",
        "carry, state_history = jax.lax.scan(sim_step, carry, None, length=1000)\n",
        "\n",
        "v_render = jax.vmap(lambda s: render_craftax_pixels(s, 64))\n",
        "# This returns an array (or pytree of arrays) where the leading axis corresponds to the time steps.\n",
        "frames_pixels = v_render(state_history)\n",
        "\n",
        "# Convert the rendered frames from JAX to NumPy (if not already on the CPU).\n",
        "frames_pixels_np = np.array(frames_pixels)\n",
        "\n",
        "# Combine the initial frame with the rest.\n",
        "# We assume that each frame is an image array.\n",
        "frames = [frame for frame in frames_pixels_np]\n",
        "\n",
        "# Save the frames as an MP4 video.\n",
        "frames_np = np.array(frames[:], dtype=np.uint8)\n",
        "imageio.mimsave('craftax_replay.mp4', frames_np, fps=30)\n",
        "print(f\"Saved {len(frames)} frames to craftax_replay.mp4\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5U6bL8Yoiov",
        "outputId": "d0eabc32-57d0-4f1f-cc85-82300196c07f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 1000 frames to craftax_replay.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v_render = jax.vmap(lambda s: render_craftax_pixels(s, 64))\n",
        "# This returns an array (or pytree of arrays) where the leading axis corresponds to the time steps.\n",
        "frames_pixels = v_render(state_history)\n",
        "\n",
        "# Convert the rendered frames from JAX to NumPy (if not already on the CPU).\n",
        "frames_pixels_np = np.array(frames_pixels)\n",
        "\n",
        "# Combine the initial frame with the rest.\n",
        "# We assume that each frame is an image array.\n",
        "frames = [frame for frame in frames_pixels_np]\n",
        "\n",
        "# Save the frames as an MP4 video.\n",
        "frames_np = np.array(frames[:], dtype=np.uint8)\n",
        "imageio.mimsave('craftax_replay.mp4', frames_np, fps=30)\n",
        "print(f\"Saved {len(frames)} frames to craftax_replay.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8yeZOpyuxLf",
        "outputId": "4da3b592-161c-46c7-f069-60ace4edf677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 101 frames to craftax_replay.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import imageio\n",
        "from craftax.craftax.envs.craftax_symbolic_env import CraftaxSymbolicEnv\n",
        "from craftax.craftax.renderer import render_craftax_symbolic\n",
        "from transformerXL import Transformer\n",
        "from trainer_PPO_trXL import ActorCriticTransformer\n",
        "\n",
        "# Load saved model parameters and config\n",
        "params = jnp.load(\"results_craftax/craftax/0_params.npy\", allow_pickle=True).item()\n",
        "config = jnp.load(\"results_craftax/craftax/0_config.npy\", allow_pickle=True).item()\n",
        "\n",
        "# Set up environment and its parameters\n",
        "env = CraftaxSymbolicEnv()\n",
        "env_params = env.default_params\n",
        "\n",
        "# Create the model\n",
        "network = ActorCriticTransformer(\n",
        "    action_dim=env.action_space(env_params).n,\n",
        "    activation=config[\"ACTIVATION\"],\n",
        "    encoder_size=config[\"EMBED_SIZE\"],\n",
        "    hidden_layers=config[\"hidden_layers\"],\n",
        "    num_heads=config[\"num_heads\"],\n",
        "    qkv_features=config[\"qkv_features\"],\n",
        "    num_layers=config[\"num_layers\"],\n",
        "    gating=config[\"gating\"],\n",
        "    gating_bias=config[\"gating_bias\"],\n",
        ")\n",
        "\n",
        "# Initialize random key and reset environment\n",
        "rng = jax.random.PRNGKey(0)\n",
        "rng, _rng = jax.random.split(rng)\n",
        "obs, state = env.reset(_rng, env_params)\n",
        "\n",
        "# Duplicate observation to create a dummy batch of size 2\n",
        "obs = obs[None, :]  # shape: (1, obs_dim)\n",
        "obs = jnp.concatenate([obs, obs], axis=0)  # now shape: (2, obs_dim)\n",
        "\n",
        "# Initialize memories and memory mask (batch size 2)\n",
        "memories = jnp.zeros((2, config[\"WINDOW_MEM\"], config[\"num_layers\"], config[\"EMBED_SIZE\"]))\n",
        "memories_mask = jnp.zeros(\n",
        "    (2, config[\"num_heads\"], 1, config[\"WINDOW_MEM\"] + 1), dtype=jnp.bool_\n",
        ")\n",
        "\n",
        "# Render initial frame (outside scan because rendering is non-JAX)\n",
        "frames = [jnp.array(render_craftax_symbolic(state))]\n",
        "\n",
        "# Define one simulation step for lax.scan and jit it.\n",
        "@jax.jit\n",
        "def simulation_step(carry, _):\n",
        "    rng, obs, state, memories, memories_mask = carry\n",
        "\n",
        "    # Get action from model (batched call)\n",
        "    rng, subkey = jax.random.split(rng)\n",
        "    pi, _, memories_out = network.apply(\n",
        "        params, memories, obs, memories_mask, method=network.model_forward_eval\n",
        "    )\n",
        "    # Sample action from the first element of the batch\n",
        "    action = pi.sample(seed=subkey)[0]\n",
        "\n",
        "    # Update memories: roll and then update the last slot\n",
        "    memories = jnp.roll(memories, -1, axis=1)\n",
        "    new_mem = memories_out[0]  # new memory from the first batch element\n",
        "    new_mem_batched = jnp.broadcast_to(new_mem, (2,) + new_mem.shape)\n",
        "    memories = memories.at[:, -1].set(new_mem_batched)\n",
        "\n",
        "    # Step environment (env.step expects unbatched state/action)\n",
        "    rng, subkey = jax.random.split(rng)\n",
        "    obs_unbatched, new_state, reward, done, info = env.step(subkey, state, action, env_params)\n",
        "    # Re-batch the observation\n",
        "    obs = jnp.concatenate([obs_unbatched[None, :], obs_unbatched[None, :]], axis=0)\n",
        "\n",
        "    new_carry = (rng, obs, new_state, memories, memories_mask)\n",
        "    # Return the updated carry and the new state for rendering\n",
        "    return new_carry, new_state\n",
        "\n",
        "# Initial carry for the scan\n",
        "init_carry = (rng, obs, state, memories, memories_mask)\n",
        "\n",
        "# Run simulation for 1000 steps using lax.scan (simulation_step is jitted)\n",
        "carry, states = jax.lax.scan(simulation_step, init_carry, None, length=1000)\n",
        "\n",
        "# Render frames from the collected states (outside the scan)\n",
        "for s in states:\n",
        "    frames.append(jnp.array(render_craftax_symbolic(s)))\n",
        "\n",
        "# Convert frames to a NumPy array and save as MP4 video\n",
        "frames_np = jnp.array(frames).astype(jnp.uint8)\n",
        "frames_np = jax.device_get(frames_np)  # transfer to CPU if needed\n",
        "imageio.mimsave('craftax_replay.mp4', frames_np, fps=30)\n",
        "print(f\"Saved {len(frames)} frames to craftax_replay.mp4\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "GaaAhxlzm9o3",
        "outputId": "bac7ffdf-6e68-49d5-b4da-6d0db95b43c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'EnvState' object is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-9ca7996e8ee2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# Render frames from the collected states (outside the scan)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender_craftax_symbolic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'EnvState' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states.map.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggmV6pMuoSFh",
        "outputId": "319a8a56-fa48-427d-9694-174577041f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 9, 48, 48)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import imageio\n",
        "from craftax.craftax.envs.craftax_symbolic_env import CraftaxSymbolicEnv\n",
        "from craftax.craftax.renderer import render_craftax_pixels\n",
        "from transformerXL import Transformer\n",
        "from trainer_PPO_trXL import ActorCriticTransformer\n",
        "\n",
        "# Load saved model parameters and config\n",
        "params = jnp.load(\"results_craftax/craftax/0_params.npy\", allow_pickle=True).item()\n",
        "config = jnp.load(\"results_craftax/craftax/0_config.npy\", allow_pickle=True).item()\n",
        "\n",
        "# Set up environment\n",
        "env = CraftaxSymbolicEnv()\n",
        "env_params = env.default_params\n",
        "\n",
        "# Create model\n",
        "network = ActorCriticTransformer(\n",
        "    action_dim=env.action_space(env_params).n,\n",
        "    activation=config[\"ACTIVATION\"],\n",
        "    encoder_size=config[\"EMBED_SIZE\"],\n",
        "    hidden_layers=config[\"hidden_layers\"],\n",
        "    num_heads=config[\"num_heads\"],\n",
        "    qkv_features=config[\"qkv_features\"],\n",
        "    num_layers=config[\"num_layers\"],\n",
        "    gating=config[\"gating\"],\n",
        "    gating_bias=config[\"gating_bias\"],\n",
        ")\n",
        "\n",
        "# Initialize random key and environment\n",
        "rng = jax.random.PRNGKey(0)\n",
        "rng, _rng = jax.random.split(rng)\n",
        "obs, state = env.reset(_rng, env_params)\n",
        "\n",
        "# IMPORTANT: In training the model was built for a batch size of 2.\n",
        "# To prevent the transformer from accidentally squeezing the batch dim (and then causing shape mismatches)\n",
        "# we duplicate our single observation to create a dummy batch.\n",
        "obs = obs[None, :]                  # shape: (1, obs_dim)\n",
        "obs = jnp.concatenate([obs, obs], axis=0)  # now shape: (2, obs_dim)\n",
        "\n",
        "# Similarly, initialize memories and mask with batch size 2.\n",
        "memories = jnp.zeros((2, config[\"WINDOW_MEM\"], config[\"num_layers\"], config[\"EMBED_SIZE\"]))\n",
        "memories_mask = jnp.zeros(\n",
        "    (2, config[\"num_heads\"], 1, config[\"WINDOW_MEM\"] + 1), dtype=jnp.bool_\n",
        ")\n",
        "\n",
        "# Collect frames (rendering uses the unbatched state)\n",
        "frames = []\n",
        "frames.append(np.array(render_craftax_symbolic(state)))\n",
        "\n",
        "print(\"Starting simulation...\")\n",
        "for i in range(100):\n",
        "    # Get action from model (batched call)\n",
        "    rng, _rng = jax.random.split(rng)\n",
        "    pi, _, memories_out = network.apply(\n",
        "        params, memories, obs, memories_mask, method=network.model_forward_eval\n",
        "    )\n",
        "    # Sample action from the first batch element (we only control one environment)\n",
        "    action = pi.sample(seed=_rng)[0]\n",
        "\n",
        "    # Update memories: roll the time dimension then update the last slot.\n",
        "    memories = jnp.roll(memories, -1, axis=1)\n",
        "    # Use the first element of the new memories to update both copies,\n",
        "    # ensuring that our fake batch stays identical.\n",
        "    new_mem = memories_out[0]  # shape: (config[\"num_layers\"], config[\"EMBED_SIZE\"])\n",
        "    new_mem_batched = jnp.broadcast_to(new_mem, (2,) + new_mem.shape)\n",
        "    memories = memories.at[:, -1].set(new_mem_batched)\n",
        "\n",
        "    # Step environment (env.step expects unbatched state/action)\n",
        "    rng, _rng = jax.random.split(rng)\n",
        "    obs_unbatched, state, reward, done, info = env.step(_rng, state, action, env_params)\n",
        "\n",
        "    # Re-batch the observation by duplicating it (to keep batch size 2)\n",
        "    obs = obs_unbatched[None, :]\n",
        "    obs = jnp.concatenate([obs, obs], axis=0)\n",
        "\n",
        "    # Render and store frame\n",
        "    frames.append(np.array(render_craftax_pixels(state,64)))\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print(f\"Completed {i} steps\")\n",
        "\n",
        "# Save collected frames as an MP4 video\n",
        "frames_np = np.array(frames[1:], dtype=np.uint8)\n",
        "imageio.mimsave('craftax_replay.mp4', frames_np, fps=30)\n",
        "print(f\"Saved {len(frames)} frames to craftax_replay.mp4\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oUnDqpekcXnH",
        "outputId": "4a41e100-5acf-4e29-df1f-074f4f0fbc59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-41f0d2694807>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# IMPORTANT: In training the model was built for a batch size of 2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     (outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked, executable,\n\u001b[0;32m--> 341\u001b[0;31m      pgle_profiler) = _python_pjit_helper(fun, jit_info, *args, **kwargs)\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     maybe_fastpath_data = _get_fastpath_data(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, jit_info, *args, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0margs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m       \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_eval_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0mout_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pjit_call_impl_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m       \u001b[0mout_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpjit_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_call_impl_python\u001b[0;34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, compiler_options_kvs, *args)\u001b[0m\n\u001b[1;32m   1655\u001b[0m       \u001b[0mpgle_profiler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpgle_profiler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m       \u001b[0mcompiler_options_kvs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompiler_options_kvs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m   ).compile()\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m   \u001b[0;31m# This check is expensive so only do it if enable_checks is on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, compiler_options)\u001b[0m\n\u001b[1;32m   2444\u001b[0m     \u001b[0mcompiler_options_kvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiler_options_kvs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt_compiler_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcompiler_options_kvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       executable = UnloadedMeshExecutable.from_hlo(\n\u001b[0m\u001b[1;32m   2447\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m           compiler_options_kvs=compiler_options_kvs)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36mfrom_hlo\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m     \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pxla_cached_compilation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2959\u001b[0;31m     xla_executable = _cached_compilation(\n\u001b[0m\u001b[1;32m   2960\u001b[0m         \u001b[0mhlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmesh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspmd_lowering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2961\u001b[0m         \u001b[0mtuple_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_spmd_lowering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_prop_to_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36m_cached_compilation\u001b[0;34m(computation, name, mesh, spmd_lowering, tuple_args, auto_spmd_lowering, allow_prop_to_inputs, allow_prop_to_outputs, host_callbacks, backend, da, pmap_nreps, compiler_options_kvs, pgle_profiler)\u001b[0m\n\u001b[1;32m   2755\u001b[0m       \u001b[0;34m\"Finished XLA compilation of {fun_name} in {elapsed_time:.9f} sec\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2756\u001b[0m       fun_name=name, event=dispatch.BACKEND_COMPILE_EVENT):\n\u001b[0;32m-> 2757\u001b[0;31m     xla_executable = compiler.compile_or_get_cached(\n\u001b[0m\u001b[1;32m   2758\u001b[0m         \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost_callbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2759\u001b[0m         pgle_profiler)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/compiler.py\u001b[0m in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, devices, compile_options, host_callbacks, pgle_profiler)\u001b[0m\n\u001b[1;32m    406\u001b[0m       \u001b[0mignore_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_key_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIgnoreCallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m     cache_key = compilation_cache.get_cache_key(\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0mcomputation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/compilation_cache.py\u001b[0m in \u001b[0;36mget_cache_key\u001b[0;34m(module, devices, compile_options, backend, ignore_callbacks)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0mignore_callbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIgnoreCallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIgnoreCallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNO\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m ) -> str:\n\u001b[0;32m--> 291\u001b[0;31m   return cache_key.get(\n\u001b[0m\u001b[1;32m    292\u001b[0m       \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/cache_key.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(module, devices, compile_options, backend, compression_algorithm, ignore_callbacks)\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mhash_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msha256\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mhashfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0m_log_cache_key_hash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhashfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m   \u001b[0msym_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sym_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/cache_key.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(hash_obj)\u001b[0m\n\u001b[1;32m    101\u001b[0m       (\n\u001b[1;32m    102\u001b[0m           \u001b[0;34m\"computation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m           lambda hash_obj: _hash_computation(\n\u001b[0m\u001b[1;32m    104\u001b[0m               \u001b[0mhash_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m           ),\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/cache_key.py\u001b[0m in \u001b[0;36m_hash_computation\u001b[0;34m(hash_obj, module, ignore_callbacks)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mcanonical_ir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_serialize_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mcanonical_ir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_canonicalize_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m   \u001b[0mhash_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanonical_ir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/jax/_src/cache_key.py\u001b[0m in \u001b[0;36m_canonicalize_ir\u001b[0;34m(m_original, ignore_callbacks)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;34m\"builtin.module(strip-debuginfo)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     )\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mpasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_serialize_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "import imageio\n",
        "\n",
        "from craftax.craftax.envs.craftax_symbolic_env import CraftaxSymbolicEnv\n",
        "from craftax.craftax.renderer import render_craftax_pixels\n",
        "from transformerXL import Transformer\n",
        "from trainer_PPO_trXL import ActorCriticTransformer\n",
        "\n",
        "def run_craftax_rollout(params, config, num_steps=100, video_filename=\"craftax_rollout.mp4\"):\n",
        "    \"\"\"\n",
        "    Fully JIT-compile a loop that runs the transformer policy and the Craftax environment\n",
        "    for `num_steps`, then render the resulting states as a video.\n",
        "\n",
        "    Requirements:\n",
        "      - CraftaxSymbolicEnv must be JAX-friendly (no hidden Python side-effects).\n",
        "      - `params` and `config` must be loaded prior to calling this function.\n",
        "      - The Transformer-based policy is from trainer_PPO_trXL.ActorCriticTransformer.\n",
        "\n",
        "    Returns:\n",
        "      None. Saves a video to `video_filename`.\n",
        "    \"\"\"\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # 1) Set up the environment and the network\n",
        "    # ----------------------------------------------------------------------\n",
        "    env = CraftaxSymbolicEnv()\n",
        "    env_params = env.default_params\n",
        "\n",
        "    # Create the Transformer policy (same as in your original code)\n",
        "    network = ActorCriticTransformer(\n",
        "        action_dim = env.action_space(env_params).n,\n",
        "        activation = config[\"ACTIVATION\"],\n",
        "        encoder_size = config[\"EMBED_SIZE\"],\n",
        "        hidden_layers = config[\"hidden_layers\"],\n",
        "        num_heads = config[\"num_heads\"],\n",
        "        qkv_features = config[\"qkv_features\"],\n",
        "        num_layers = config[\"num_layers\"],\n",
        "        gating = config[\"gating\"],\n",
        "        gating_bias = config[\"gating_bias\"],\n",
        "    )\n",
        "\n",
        "    # Random keys\n",
        "    rng = jax.random.PRNGKey(0)\n",
        "    rng, rng_reset = jax.random.split(rng)\n",
        "\n",
        "    # Reset environment (unbatched)\n",
        "    obs, state = env.reset(rng_reset, env_params)\n",
        "\n",
        "    # Make sure we have batch dimension = 2 (to match training code)\n",
        "    obs = obs[None, :]                        # shape (1, obs_dim)\n",
        "    obs = jnp.concatenate([obs, obs], axis=0) # shape (2, obs_dim)\n",
        "\n",
        "    # Initialize memories and mask (batch=2)\n",
        "    memories = jnp.zeros((2, config[\"WINDOW_MEM\"], config[\"num_layers\"], config[\"EMBED_SIZE\"]))\n",
        "    memories_mask = jnp.zeros((2, config[\"num_heads\"], 1, config[\"WINDOW_MEM\"] + 1), dtype=jnp.bool_)\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # 2) Define the one-step function for lax.scan\n",
        "    # ----------------------------------------------------------------------\n",
        "    def scan_step(carry, t):\n",
        "        \"\"\"\n",
        "        carry = (rng, memories, obs, state)\n",
        "        t is just the current step index (unused except for array indexing)\n",
        "\n",
        "        Returns:\n",
        "          new_carry, out\n",
        "        where\n",
        "          new_carry = (rng, updated_memories, updated_obs, updated_state)\n",
        "          out = (state, reward, done)\n",
        "        \"\"\"\n",
        "        (rng, memories, obs, state) = carry\n",
        "\n",
        "        # Split RNG\n",
        "        rng, rng_action, rng_step = jax.random.split(rng, 3)\n",
        "\n",
        "        # Forward pass through Transformer\n",
        "        pi, _, memories_out = network.apply(\n",
        "            params,\n",
        "            memories,\n",
        "            obs,\n",
        "            memories_mask,\n",
        "            method=network.model_forward_eval\n",
        "        )\n",
        "        # Sample action from the first batch element\n",
        "        action = pi.sample(seed=rng_action)[0]\n",
        "\n",
        "        # Roll the memory along the time dimension\n",
        "        memories = jnp.roll(memories, shift=-1, axis=1)\n",
        "        new_mem = memories_out[0]  # shape: (num_layers, EMBED_SIZE)\n",
        "\n",
        "        # Broadcast the new memory to both batch elements (to keep them in sync)\n",
        "        new_mem_batched = jnp.broadcast_to(new_mem, (2,) + new_mem.shape)\n",
        "        memories = memories.at[:, -1].set(new_mem_batched)\n",
        "\n",
        "        # Step the environment (JAX-friendly!)\n",
        "        obs_unbatched, new_state, reward, done, info = env.step(rng_step, state, action, env_params)\n",
        "\n",
        "        # Re-batch obs\n",
        "        new_obs = jnp.concatenate([obs_unbatched[None, :], obs_unbatched[None, :]], axis=0)\n",
        "\n",
        "        new_carry = (rng, memories, new_obs, new_state)\n",
        "        out = (new_state, reward, done)\n",
        "        return new_carry, out\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # 3) Wrap the scan in a JIT-compiled function\n",
        "    # ----------------------------------------------------------------------\n",
        "    @jax.jit\n",
        "    def run_scan(rng, memories, obs, state):\n",
        "        \"\"\"\n",
        "        Runs `num_steps` of the environment+policy using lax.scan.\n",
        "        Returns final carry + entire trajectory of (state, reward, done).\n",
        "        \"\"\"\n",
        "        init_carry = (rng, memories, obs, state)\n",
        "        # We just create an array of indices [0..num_steps-1] to \"drive\" the scan.\n",
        "        step_indices = jnp.arange(num_steps)\n",
        "\n",
        "        final_carry, trajectory = jax.lax.scan(scan_step, init_carry, step_indices)\n",
        "        # trajectory has shape (num_steps, 3, ...), where 3 corresponds to (state, reward, done).\n",
        "        return final_carry, trajectory\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # 4) Actually run the JIT'ed rollout\n",
        "    # ----------------------------------------------------------------------\n",
        "    final_carry, trajectory = run_scan(rng, memories, obs, state)\n",
        "    # final_carry is (rng, memories, obs, state) after the last step\n",
        "    # trajectory is shape (num_steps, 3) if each item is a scalar or array.\n",
        "    # But specifically:\n",
        "    #   trajectory[0] -> array of shape (num_steps, ) if it's a scalar\n",
        "    #   trajectory[1] -> ...\n",
        "    #   trajectory[2] -> ...\n",
        "    #\n",
        "    # We stored (state, reward, done), so let's unpack that:\n",
        "    states, rewards, dones = trajectory\n",
        "\n",
        "    # ----------------------------------------------------------------------\n",
        "    # 5) Render frames (outside of JIT), then write to file.\n",
        "    # ----------------------------------------------------------------------\n",
        "    # states is shape (num_steps, ...) with each element an environment state (unbatched).\n",
        "    # We'll loop in Python to convert each state to a frame using render_craftax_pixels.\n",
        "    # That call is presumably CPU-based and might be slow, so do it once here.\n",
        "    frames = []\n",
        "    for i in range(num_steps):\n",
        "        # states[i] is the environment state\n",
        "        frame = np.array(render_craftax_pixels(states[i], scale=4))  # scale=4 if you like\n",
        "        frames.append(frame)\n",
        "\n",
        "    # Save to video\n",
        "    frames_np = np.array(frames, dtype=np.uint8)\n",
        "    imageio.mimsave(video_filename, frames_np, fps=30)\n",
        "    print(f\"Saved {len(frames)} frames to {video_filename}.\")\n",
        "\n",
        "    return\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0VxX5gEGtxx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames_np = np.array(frames[1:], dtype=np.uint8)\n",
        "imageio.mimsave('craftax_replay.mp4', frames_np, fps=30)\n",
        "print(f\"Saved {len(frames)} frames to craftax_replay.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjLnKY9YnB6r",
        "outputId": "95c5ef9d-5de0-4d90-98e3-a54e69460d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.11/subprocess.py:1885: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _fork_exec(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 101 frames to craftax_replay.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frames_np = np.array(frames, dtype=np.uint8)\n",
        "imageio.mimsave('craftax_replay.mp4', frames_np, fps=30)\n",
        "print(f\"Saved {len(frames)} frames to craftax_replay.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "7Jg14kN-fh8F",
        "outputId": "80207fa7-0580-453d-9000-808a04c1cc39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Image data must be a sequence of ndimages.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-ced457119408>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mframes_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'craftax_replay.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Saved {len(frames)} frames to craftax_replay.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imageio/v2.py\u001b[0m in \u001b[0;36mmimwrite\u001b[0;34m(uri, ims, format, **kwargs)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image data must be a sequence of ndimages.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[0mimopen_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecypher_format_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Image data must be a sequence of ndimages."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "2+2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INMlzyYygtTH",
        "outputId": "61acdbaa-7f19-4d58-f16e-f39701a8238a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZP_vSiZ3lIAN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}